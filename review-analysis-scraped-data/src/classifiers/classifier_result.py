# src/classifiers/classifier_result.py


import os
import re
import numpy as np
import pandas as pd
from decorators import pipeline_step
from config import logger, SAVE_STEP_12_RESULT, PROCESSED_DIR, TIMESTAMP

@pipeline_step(step_number=12, step_name="–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† RESULT ‚Äî –ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å")
def classifier_result(df, stop_pipeline_flag=False, step_number=12):
    """
    –ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å —É—á—ë—Ç–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –∫–ª–∞—Å—Å–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ –∫–æ–¥–æ–≤),
    –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ–º –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º,
    –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ 202,
    —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ DOCX-–æ—Ç—á—ë—Ç–æ–º —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ –∏—Ç–æ–≥–∞–º–∏.

    –ó–Ω–∞—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –±–µ–∑ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è,
    –∞ –¥–æ–ª—è –≤ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö ‚Äî —Å 2 –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π.
    """

    if stop_pipeline_flag:
        logger.warning(f"üîö [{step_number}] –®–∞–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return df

    if df is None or df.empty:
        logger.warning(f"üü° [{step_number}] –í—Ö–æ–¥–Ω–æ–π DataFrame –ø—É—Å—Ç–æ–π –∏–ª–∏ None")
        return df

    if "–ö–ª–∞—Å—Å" not in df.columns:
        logger.error(f"‚ùå [{step_number}] –í—Ö–æ–¥–Ω–æ–π DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É '–ö–ª–∞—Å—Å'")
        return df

    rules_dict = {
        '0': (1, 1),
        '100': (1, 1),
        '999': (999, 2),
        '700': (7, 3),
        '500': (5, 4),
        '300': (3, 5),
        '200': (2, 6),
        '201': (2, 6),
        '202': (2, 6),
        '701': (7, 7),
    }

    def parse_class_codes(c):
        import numpy as np

        if isinstance(c, (list, tuple, np.ndarray)):
            return [str(x).strip() for x in c if str(x).strip() != '']

        if pd.isna(c):
            return []

        if isinstance(c, str):
            c = c.strip()
            if c.startswith("[") and c.endswith("]"):
                try:
                    import ast
                    parsed = ast.literal_eval(c)
                    if isinstance(parsed, (list, tuple)):
                        return [str(x).strip() for x in parsed if str(x).strip() != '']
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É –≤ —Å–ø–∏—Å–æ–∫: {c}, –æ—à–∏–±–∫–∞: {e}")
            if ',' in c:
                parts = c.split(',')
                return [p.strip() for p in parts if p.strip() != '']
            return [c] if c else []

        if hasattr(c, 'values'):
            return [str(x).strip() for x in c.values.flatten() if str(x).strip() != '']

        if hasattr(c, '__iter__') and not isinstance(c, (str, bytes)):
            try:
                return [str(x).strip() for x in c if str(x).strip() != '']
            except Exception:
                pass

        if isinstance(c, (int, float)):
            return [str(int(c))] if int(c) == c else [str(c)]

        return [str(c).strip()]

    def parse_probs_from_note(note):
        if not isinstance(note, str):
            return (np.nan, np.nan)
        pos_match = re.search(r'pos=([0-9]*\.?[0-9]+)', note)
        neu_match = re.search(r'neu=([0-9]*\.?[0-9]+)', note)
        pos_prob = float(pos_match.group(1)) if pos_match else np.nan
        neu_prob = float(neu_match.group(1)) if neu_match else np.nan
        return pos_prob, neu_prob

    df = df.copy()

    if ('prob_positive_202' not in df.columns or 'prob_neutral_202' not in df.columns) or \
       df['prob_positive_202'].isna().all() or df['prob_neutral_202'].isna().all():
        probs = df['–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ'].apply(parse_probs_from_note)
        df['prob_positive_202'] = [p[0] for p in probs]
        df['prob_neutral_202'] = [p[1] for p in probs]

    for col in ['prob_positive_202', 'prob_neutral_202']:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace(',', '.').astype(float, errors='ignore')

    df['class_codes_list'] = df['–ö–ª–∞—Å—Å'].apply(parse_class_codes)
    df['class_codes_tuple'] = df['class_codes_list'].apply(lambda codes: tuple(sorted(set(codes))))

    def assign_result_class_by_codes(codes_tuple):
        candidates = []
        for code in codes_tuple:
            if code in rules_dict:
                candidates.append(rules_dict[code])
        if not candidates:
            return None
        candidates.sort(key=lambda x: x[1])
        return candidates[0][0]

    df['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'] = df['class_codes_tuple'].apply(assign_result_class_by_codes)

    total_count = len(df)

    summary_data = []
    classes_present = df['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'].dropna().unique()
    for cls in sorted(classes_present, key=lambda x: (float('inf') if x is None else x)):
        sub_df = df[df['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'] == cls]
        count = len(sub_df)
        share = count / total_count if total_count > 0 else 0.0
        codes_lists = sub_df['–ö–ª–∞—Å—Å'].apply(parse_class_codes)
        unique_codes = set(code for clist in codes_lists for code in clist)

        if cls == 202:
            avg_prob_pos = sub_df['prob_positive_202'].mean(skipna=True)
            avg_prob_neu = sub_df['prob_neutral_202'].mean(skipna=True)
        else:
            avg_prob_pos = None
            avg_prob_neu = None

        summary_data.append({
            "–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å": cls,
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤": count,
            "–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ": round(share, 4),  # –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ 4 –∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏, –Ω–æ –≤ –≤—ã–≤–æ–¥–µ –æ–∫—Ä—É–≥–ª–∏–º –¥–æ 2
            "–ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–¥—ã '–ö–ª–∞—Å—Å'": ", ".join(sorted(unique_codes)),
            "–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π 202": avg_prob_pos if avg_prob_pos is not None else "",
            "–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π 202": avg_prob_neu if avg_prob_neu is not None else "",
        })
    summary_df = pd.DataFrame(summary_data)

    detail_group = (
        df.groupby(['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å', 'class_codes_tuple'])
        .size()
        .reset_index(name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤')
    )
    detail_group['–î–æ–ª—è'] = detail_group['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'] / total_count
    detail_group['–ö–ª–∞—Å—Å'] = detail_group['class_codes_tuple'].apply(lambda tup: "[" + ", ".join(tup) + "]")
    detail_group = detail_group[['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å', '–ö–ª–∞—Å—Å', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤', '–î–æ–ª—è']]

    summary_row = pd.DataFrame({
        '–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å': ['–ò—Ç–æ–≥–æ:'],
        '–ö–ª–∞—Å—Å': ['-'],
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤': [detail_group['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'].sum()],
        '–î–æ–ª—è': [detail_group['–î–æ–ª—è'].sum()]
    })
    detail_group = pd.concat([detail_group, summary_row], ignore_index=True)

    for col in ['class_codes_list', 'class_codes_tuple']:
        if col in df.columns:
            df.drop(columns=[col], inplace=True)

    if SAVE_STEP_12_RESULT:
        result_file = os.path.join(PROCESSED_DIR, f"step_{step_number}_result_classification_{TIMESTAMP}.xlsx")
        docx_file = os.path.join(PROCESSED_DIR, f"step_{step_number}_result_classification_summary_{TIMESTAMP}.docx")

        try:
            with pd.ExcelWriter(result_file) as writer:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –ø–æ–ª–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –¥–æ–ª—é –≤—ã–≤–æ–¥–∏–º —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 2 –∑–Ω–∞–∫–∞
                df.to_excel(writer, index=False, sheet_name="–û—Ç–∑—ã–≤—ã —Å –∏—Ç–æ–≥–æ–≤—ã–º –∫–ª–∞—Å—Å–æ–º")

                # –û–∫—Ä—É–≥–ª—è–µ–º –î–æ–ª—é –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –¥–ª—è summary_df (—Ç–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª—å–Ω–æ)
                summary_df_to_save = summary_df.copy()
                summary_df_to_save['–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ'] = summary_df_to_save['–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ'].round(2)
                summary_df_to_save.to_excel(writer, index=False, sheet_name="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤")

                # –î–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–∞–∫–∂–µ –æ–∫—Ä—É–≥–ª—è–µ–º –î–æ–ª—è –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
                detail_group_to_save = detail_group.copy()
                detail_group_to_save['–î–æ–ª—è'] = detail_group_to_save['–î–æ–ª—è'].round(2)
                detail_group_to_save.to_excel(writer, index=False, sheet_name="–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º")

            logger.info(f"üìå [{step_number}]: –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª {result_file}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [{step_number}]: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}")

        try:
            from docx import Document
            from docx.shared import Pt
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            from docx.oxml.ns import qn

            doc = Document()

            style = doc.styles['Normal']
            font = style.font
            font.name = 'Calibri'
            font.size = Pt(11)
            rFonts = style.element.rPr.rFonts
            rFonts.set(qn('w:eastAsia'), 'Calibri')

            heading = doc.add_heading('–ò—Ç–æ–≥–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–∑—ã–≤–æ–≤', level=1)
            heading.alignment = WD_ALIGN_PARAGRAPH.CENTER

            doc.add_paragraph(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {TIMESTAMP}")
            doc.add_paragraph(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {total_count}")
            doc.add_paragraph("")

            table = doc.add_table(rows=1, cols=4)
            table.style = 'LightShading-Accent1'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = '–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'
            hdr_cells[1].text = '–ö–ª–∞—Å—Å'
            hdr_cells[2].text = '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'
            hdr_cells[3].text = '–î–æ–ª—è'

            detail_no_total = detail_group[detail_group['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'] != '–ò—Ç–æ–≥–æ:']

            for group_key, group_df in detail_no_total.groupby('–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'):
                for _, row in group_df.iterrows():
                    cells = table.add_row().cells
                    cells[0].text = str(row['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'])
                    cells[1].text = str(row['–ö–ª–∞—Å—Å'])
                    cells[2].text = str(row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'])
                    # –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∏–¥–∞ –≤ docx
                    cells[3].text = f"{row['–î–æ–ª—è']*100:.2f}%"

                    for idx, cell in enumerate(cells):
                        for paragraph in cell.paragraphs:
                            if idx < 2:
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                            else:
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                total_reviews = group_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'].sum()
                total_share = group_df['–î–æ–ª—è'].sum()
                cells = table.add_row().cells
                cells[0].text = f"–≤—Å–µ–≥–æ –ø–æ –∫–ª–∞—Å—Å—É {group_key}"
                cells[1].text = ""
                cells[2].text = str(total_reviews)
                cells[3].text = f"{total_share*100:.2f}%"

                for idx, cell in enumerate(cells):
                    for paragraph in cell.paragraphs:
                        paragraph.runs[0].font.bold = True
                        if idx < 2:
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        else:
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

            total_row = detail_group[detail_group['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'] == '–ò—Ç–æ–≥–æ:'].iloc[0]
            cells = table.add_row().cells
            cells[0].text = str(total_row['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å'])
            cells[1].text = str(total_row['–ö–ª–∞—Å—Å'])
            cells[2].text = str(total_row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤'])
            cells[3].text = f"{total_row['–î–æ–ª—è']*100:.2f}%"

            for idx, cell in enumerate(cells):
                for paragraph in cell.paragraphs:
                    paragraph.runs[0].font.bold = True
                    if idx < 2:
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    else:
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

            doc.save(docx_file)
            logger.info(f"üìå [{step_number}]: –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ –∏—Ç–æ–≥–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ DOCX-—Ñ–∞–π–ª {docx_file}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [{step_number}]: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ DOCX —Ñ–∞–π–ª–∞: {e}")

    logger.info(f"üî¢ [{step_number}] –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    for _, row in summary_df.iterrows():
        pos_prob_str = (
            f", —Å—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π 202: {row['–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π 202']}"
            if row.get('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–π 202') != "" else ""
        )
        neu_prob_str = (
            f", —Å—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π 202: {row['–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π 202']}"
            if row.get('–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π 202') != "" else ""
        )
        logger.info(
            f"–ö–ª–∞—Å—Å {row['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å']}: {row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤']} –æ—Ç–∑—ã–≤–æ–≤, "
            f"–¥–æ–ª—è {row['–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ']:.2f}, –∫–æ–¥—ã: {row['–ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–¥—ã \'–ö–ª–∞—Å—Å\'']}"
            + pos_prob_str + neu_prob_str
        )

    logger.info(f"üî¢ [{step_number}] –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Ç–æ–≥–æ–≤—ã–º –∫–ª–∞—Å—Å–∞–º –∏ –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–∞–º:")
    for _, row in detail_group.iterrows():
        cls = row['–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å']
        code = row['–ö–ª–∞—Å—Å']
        count = row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤']
        share_pct = row['–î–æ–ª—è'] * 100
        if str(cls).lower() == '–∏—Ç–æ–≥–æ:':
            continue
        logger.info(f"–ò—Ç–æ–≥–æ–≤—ã–π –∫–ª–∞—Å—Å {cls}, –ö–ª–∞—Å—Å {code}: {count} –æ—Ç–∑—ã–≤–æ–≤, –¥–æ–ª—è {share_pct:.2f}%")

    return df
