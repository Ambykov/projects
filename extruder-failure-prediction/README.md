# 🚀 `extruder-failure-prediction`
**Прогнозирование тока экструдера на основе временных рядов**

> Реализация ИИ-системы для моделирования поведения оборудования на линии с экструдерами.
> Проект включает анализ данных, подбор модели, обучение и интеграцию с реальными данными в реальном времени.
> **Финальная модель:** гибрид CNN + BiLSTM + Attention + GRU
> **MAE (тест):** 41.05 | **Horizon:** до 60 минут

---

## 📌 О проекте

Цель проекта — создать **прогнозирующую модель** для тока экструдера (тег `value_14`) на основе исторических данных с промышленного оборудования.
Работа выполнена в рамках стажировки и включает:
- 💡 Анализ временных рядов (EDA, стационарность, ACF, спектр)
- 🧠 Обучение 4 гибридных моделей с механизмом внимания
- 🔍 Автоподбор гиперпараметров (Keras Tuner)
- 🔄 Интеграция с БД и работающий пайплайн в реальном времени

---

## 🧩 Ключевые компоненты

| Компонент        | Описание                                           |
|------------------|----------------------------------------------------|
| **`notebooks/`** | Jupyter-ноутбуки: от EDA до обучения модели        |
| **`models/`**    | Финальная модель `model_2_var_1.keras` и скалеры   |
| **`src/`**       | Полноценный пайплайн: загрузка, обработка, прогноз |
| **`reports/`**   | PDF-отчёты по анализу и выбору модели           |
| **`result/`**    | Выходные файлы: признаки и прогнозы                |
| **`logs/`**      | Логи работы пайплайна                              |

---

## 🔄 Архитектура пайплайна

```
    A[main.py] --> B[load_data.py]
    B --> C[export_data_by_tag.py]
    C --> D[БД (PostgreSQL)]
    B --> E[clean_data.py]
    E --> F[calculate_features.py]
    F --> G[calculated_features.csv]
    A --> H[forecast.py]
    H --> I[Загрузка модели и скалеров]
    I --> J[Прогнозирование]
    J --> K[forecasts.csv]
    H --> L[Логирование]
    L --> M[logs/pipeline.log]
```

### Как работает:
1. **`main.py`** запускает два асинхронных процесса.
2. **`load_data.py`**:
   - Получает данные за последние 10 секунд из БД
   - Чистит, восстанавливает временной ряд
   - Добавляет 48 признаков (лаги, скользящие средние и др.)
   - Сохраняет в `result/calculated_features.csv`
3. **`forecast.py`**:
   - Читает признаки
   - Масштабирует
   - Прогнозирует `value_14` на 300 сек вперёд
   - Сравнивает с реальными значениями
   - Сохраняет в `result/forecasts.csv`

---

## 🏆 Выбор модели

### Сравнение 4 гибридных архитектур:

| Модель                | MAE (обучение) | MAE (тест) | Median RE (тест) |
|-----------------------|----------------|------------|------------------|
| №1_авто               | 37.78          | 41.48      | 14.38%           |
| **№2_авто (выбрана)** | **36.01**      | **39.55**  | **13.96%** ✅    |
| №3_авто               | 40.24          | 43.59      | 14.94%           |
| №4_авто               | 37.15          | 40.94      | 14.73%           |

✅ **Модель №2** показала наилучшее качество и стабильность.

### Архитектура финальной модели:
```
Conv1D → MaxPooling1D → BiLSTM → Attention → GRU → Dense
```
- Гиперпараметры подобраны через **Keras Tuner**
- Используется механизм **многоточечного внимания**
- Поддерживает прогноз на **10–60 минут вперёд**

---

## 📊 Результаты прогноза

| Горизонт          | MAE (тест) |
|-------------------|------------|
| 10 мин (20 лагов) | **136.43** |
| 20 мин            | 137.92     |
| 30 мин            | 139.96     |
| 60 мин            | 147.28     |

> 🔹 Качество снижается с ростом горизонта — ожидаемо.

---

## ⚙️ Настройки (`config.py`)

```
TAGS = [10, 14, 16]           # Теги для прогнозирования
CHUNK_SECONDS = 10            # Шаг между точками
LOOK_BACK = 20                # Окно модели (200 сек)
FORECAST_HORIZON = 30         # Горизонт прогноза (300 сек)
MODEL_PATH = "models/model_2_var_1.keras"
```

---

## 📦 Как запустить

1. Установи зависимости:
   ```
   pip install -r requirements.txt
   ```

2. Положи обученные файлы в `models/`:
   - `model_2_var_1.keras`
   - `scaler_features.pkl`
   - `scaler_target.pkl`

3. Запусти пайплайн:
   ```
   python src/main.py
   ```

4. Результаты:
   - Признаки: `result/calculated_features.csv`
   - Прогнозы: `result/forecasts.csv`
   - Логи: `logs/pipeline.log`

---

## 📄 Отчёты

| Документ                          | Описание                                           |
|-----------------------------------|----------------------------------------------------|
| reports/eda_summary.pdf           | Анализ распределения, выбросов, режимов работы     |
| reports/pre_forecast_analysis.pdf | Стационарность, ACF, спектр, обоснование выбора ML |
| reports/final_model_selection.pdf | Сравнение 4 моделей, автоподбор гиперпараметров    |
| reports/integration_pipeline.pdf  | Описание архитектуры пайплайна                     |

---

## 🛠 Требования (`requirements.txt`)

```
pandas
numpy
tensorflow
scikit-learn
joblib
psycopg2-binary
```

---

## ✅ Что можно улучшить

- 📊 Визуализация: добавить Streamlit-дэшборд
- 🧪 Тесты: `tests/test_features.py`
- 🐳 Docker: упростить развёртывание
- 📈 Мониторинг: отслеживание качества прогноза
- 📂 Версионирование данных: DVC

---

## 🏁 Заключение

Проект демонстрирует **полный цикл ML-разработки**:
- от анализа данных → к обучению моделей → к интеграции в продакшн.
- Показывает умение работать с **реальными промышленными данными**.
- Готов к использованию в портфолио, на собеседовании или как отчёт по стажировке.

---

> 🙌 Разработано: Андрей Быков
> 📅 2025 г. | Стажировка по направлению "AI/ML-разработка"
```
