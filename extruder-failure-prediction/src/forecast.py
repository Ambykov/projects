# forecast.py

import asyncio
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler
import joblib
import os
import logging
from datetime import datetime, timedelta

from config import (
    MODEL_PATH,
    FEATURES_SCALER_PATH,
    TARGET_SCALER_PATH,
    LOOK_BACK,
    FORECAST_HORIZON,
    REQUIRED_FEATURES,
    RESULT_DIR,
    SLEEP_INTERVAL
)

logger = logging.getLogger(__name__)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–∞–ª–µ—Ä–æ–≤ === #
try:
    model = load_model(MODEL_PATH)
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    raise

try:
    with open(FEATURES_SCALER_PATH, 'rb') as f:
        scaler_features = joblib.load(f)
    logger.info("‚úÖ –°–∫–∞–ª–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∫–∞–ª–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
    raise

try:
    with open(TARGET_SCALER_PATH, 'rb') as f:
        scaler_target = joblib.load(f)
    logger.info("‚úÖ –°–∫–∞–ª–µ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∂–µ–Ω")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∫–∞–ª–µ—Ä–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {e}")
    raise


def calculate_deviation(real, predicted):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"""
    if real is None or np.isnan(real) or np.isnan(predicted):
        return np.nan, np.nan
    abs_dev = abs(real - predicted)
    rel_dev = abs_dev / real if real != 0 else 0
    return abs_dev, rel_dev


async def predict_forecasts():
    """
    –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ value_14 –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ forecasts.csv
    """

    input_path = os.path.join(RESULT_DIR, "calculated_features.csv")
    output_path = os.path.join(RESULT_DIR, "forecasts.csv")

    # === –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ calculated_features.csv === #
    if not os.path.exists(input_path):
        logger.warning("‚ö†Ô∏è –§–∞–π–ª calculated_features.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –ñ–¥—ë–º –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        return

    try:
        input_df = pd.read_csv(input_path)
        input_df['source_time'] = pd.to_datetime(input_df['source_time'])
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–ª–æ–Ω–æ–∫
    input_df = input_df.loc[:, ~input_df.columns.duplicated()]
    input_df.sort_values('source_time', inplace=True)
    input_df.reset_index(drop=True, inplace=True)

    # === –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ñ–∏—á–µ–π === #
    missing_features = set(REQUIRED_FEATURES) - set(input_df.columns)
    if missing_features:
        logger.warning(f"[WARN] –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏: {missing_features}. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
        return

    # === –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ === #
    X_data = input_df[REQUIRED_FEATURES].values
    y_data = input_df['value_14'].values

    if len(X_data) < LOOK_BACK + FORECAST_HORIZON:
        logger.warning(f"‚è≥ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–∫–Ω–∞ ({len(X_data)} / {LOOK_BACK + FORECAST_HORIZON})")
        return

    # === –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ–∫–æ–Ω === #
    windows = []
    prediction_times = []

    for i in range(LOOK_BACK, len(X_data) - FORECAST_HORIZON + 1):
        window = X_data[i - LOOK_BACK:i]
        prediction_times.append(input_df.iloc[i]['source_time'])
        windows.append(window)

    if not windows:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –æ–∫–æ–Ω –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞")
        return

    # === –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ === #
    try:
        scaled_X = scaler_features.transform(np.concatenate(windows))
        reshaped_scaled_X = scaled_X.reshape(len(windows), LOOK_BACK, -1)
    except ValueError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return

    # === –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è === #
    predictions = model.predict(reshaped_scaled_X, verbose=0)
    predicted_values = scaler_target.inverse_transform(predictions).flatten()

    # === –í—Ä–µ–º—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (—á–µ—Ä–µ–∑ FORECAST_HORIZON —à–∞–≥–æ–≤ √ó 10 —Å–µ–∫—É–Ω–¥) === #
    forecast_times = [t + timedelta(seconds=FORECAST_HORIZON * 10) for t in prediction_times]

    # === –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ FORECAST_HORIZON —à–∞–≥–æ–≤ –Ω–∞–∑–∞–¥ === #
    actual_indices = [i + FORECAST_HORIZON for i in range(len(prediction_times))]
    actual_values = [y_data[idx] if idx < len(y_data) else np.nan for idx in actual_indices]

    # === –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è === #
    deviations = [calculate_deviation(actual, pred) for actual, pred in zip(actual_values, predicted_values)]

    # === –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ === #
    min_len = min(
        len(prediction_times),
        len(forecast_times),
        len(predicted_values),
        len(actual_values),
        len([d[0] for d in deviations]),
        len([d[1] for d in deviations])
    )

    forecasts_df = pd.DataFrame({
        'prediction_time': prediction_times[-min_len:],
        'forecast_time': forecast_times[-min_len:],
        'predicted_value_14': predicted_values[-min_len:],
        'actual_value_14': actual_values[-min_len:]
    })

    # === –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∑–æ–Ω—É –∫ –º–µ—Ç–∫–∞–º –≤—Ä–µ–º–µ–Ω–∏ === #
    #forecasts_df['prediction_time'] += timedelta(hours=3)
    #forecasts_df['forecast_time'] += timedelta(hours=3)

    # === –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–µ–∑–∫–∏ –¥–æ min_len === #
    abs_devs = [d[0] for d in deviations][-min_len:]
    rel_devs = [d[1] for d in deviations][-min_len:]

    # === –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ === #
    forecasts_df['abs_deviation'] = abs_devs
    forecasts_df['rel_deviation'] = rel_devs

    # === –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 —Å—Ç—Ä–æ–∫ === #
    final_forecasts = forecasts_df.tail(30)

    # === –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª === #
    file_exists = os.path.exists(output_path)
    final_forecasts.to_csv(output_path, index=False, mode='a', header=not file_exists)
    logger.info(f"‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")


async def run_forecasting(stop_event):
    logger.info("üöÄ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ")
    while not stop_event.is_set():
        await predict_forecasts()
        await asyncio.sleep(SLEEP_INTERVAL)